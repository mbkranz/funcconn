{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/Applications/anaconda/lib/python2.7/site-packages/brainx/__init__.py:30: UserWarning: Monkeypatching NetworkX's Watts-Strogatz routine\n",
      "  warnings.warn(\"Monkeypatching NetworkX's Watts-Strogatz routine\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nibabel import freesurfer as fs\n",
    "import networkx as nx\n",
    "import brainx as bx\n",
    "from brainx import weighted_modularity as wmod\n",
    "from brainx.nodal_roles import (within_community_degree,\n",
    "                               participation_coefficient)\n",
    "from brainx.metrics import (weighted_degree)\n",
    "from brainx.weighted_modularity import LouvainCommunityDetection\n",
    "import os\n",
    "import re\n",
    "import copy\n",
    "import time\n",
    "import cPickle as pkl\n",
    "from joblib import Parallel,delayed\n",
    "import warnings\n",
    "idx=pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Edge:\n",
    "    '''create functional connectivity edge series with node and edge indices \n",
    "    roottxt : suffix of text file str\n",
    "    (e.g., '.Schaefer2018_{}'+'Parcels_7Networks_{}')\n",
    "    numparc : number of parcellations in Schaefer annot to use (e.g., '200')\n",
    "    sub : sub folder string (e.g., 'ACT01_1')\n",
    "    funcdir : directory structure str to have specific vars added\n",
    "    ftype : type of functional data collected (e.g., 'rest') \n",
    "    run : run folder within subject and task (e.g., '001' or 'average')\n",
    "    mscrub : scrubbing parameter (e.g., '0.5')\n",
    "    nuis : str folder name of nuisance variables (compcor_ncomponents_5...)\n",
    "    band : str folder name (e.g., '0.009.0.1')\n",
    "    '''\n",
    "    def __init__(self,sub,adjcsvdir,\n",
    "                 community_sets=None,community_key=None,\n",
    "                 annotpwd=None,fsavg='fsaverage5',numparc='200'):\n",
    "        '''starts by importing a correlation matrix and setting other\n",
    "        variables'''\n",
    "        self.community_sets=community_sets\n",
    "        self.fsavg=fsavg\n",
    "        self.numparc=numparc\n",
    "        self.sub=sub\n",
    "        self.threshold=None\n",
    "        self.cost=None\n",
    "        self.adj_csvdir=adjcsvdir\n",
    "        self.adj_df=pd.read_csv(adjcsvdir)\n",
    "        self.numnodes=len(self.adj_df)\n",
    "        self.adj_df.index=pd.Index(range(self.numnodes),name='parc_y')\n",
    "        self.adj_df.columns=pd.Index(range(self.numnodes),name='parc_x')\n",
    "        self.nodes=range(self.numnodes)\n",
    "    \n",
    "    def format_adj_df(self,x_node_names=['parc_x']):\n",
    "        '''maintain info in only one diagonal of adj matrix and stacks\n",
    "        which returns a pd.Dataframe of edge weights with each node identified\n",
    "        \n",
    "        x_node_names : column names to stack (ie melt)the adj matrix by.\n",
    "        if you have already added communities, you'll want the default option,\n",
    "        if no communities, then [parc_x] only.\n",
    "        - note: stacking automatically removes na vals \n",
    "        (created from the np.tril_indices) \n",
    "        '''\n",
    "        adj_df=self.adj_df\n",
    "        adj_df.values[np.tril_indices_from(adj_df)]=np.nan\n",
    "        self.edges_series=adj_df.stack(x_node_names)\n",
    "        self.edges_series.name='weight'\n",
    "    \n",
    "    def normalize(self):\n",
    "        '''use brainx util to make edges all positive'''\n",
    "        norm_series=bx.util.normalize(self.edges_series)\n",
    "        self.edges_series=norm_series\n",
    "        \n",
    "    def find_thresh_edges(self,cost):\n",
    "        '''find the threshold correlation associated with\n",
    "        cost (density) of edges to use.\n",
    "        '''\n",
    "        es=self.edges_series\n",
    "        tot_edges=len(es)\n",
    "        num_edges_tokeep=cost*tot_edges\n",
    "        #may want to make more like brainx???\n",
    "        num_edges_tokeep_int=np.int(num_edges_tokeep)\n",
    "        es.sort_values(ascending=False,inplace=True)\n",
    "        threshold=es.iloc[num_edges_tokeep_int]\n",
    "        self.cost=cost\n",
    "        self.threshold=threshold\n",
    "        \n",
    "    def make_nxGraph(self,binary=False):\n",
    "        '''make a networkx graph with formatted edges\n",
    "        loops through nodes (as defined by how I defined\n",
    "        nodes in adjacency matrix in init).\n",
    "        loops through the edges_series object containing\n",
    "        the edges (containing only filtered if thresholded)\n",
    "        '''\n",
    "        es=self.edges_series\n",
    "        if self.threshold:\n",
    "            es_filt=bx.util.normalize(es[es>self.threshold])\n",
    "            edges_df=es_filt.reset_index()\n",
    "        else:\n",
    "            edges_df=es.reset_index()\n",
    "        if binary:\n",
    "            edges_df['weight']=1\n",
    "        graph=nx.Graph()\n",
    "        self.graph=graph\n",
    "        #loop through nodes and edges\n",
    "        for node in self.nodes:\n",
    "            graph.add_node(node)\n",
    "        for group,edge in edges_df.iterrows():\n",
    "            graph.add_edge(u=edge['parc_x'],\n",
    "                           v=edge['parc_y'],\n",
    "                           weight=edge['weight'])\n",
    "    \n",
    "    def add_GraphPartition(self,runLouvain=True):\n",
    "        '''make a Graph Partition object\n",
    "        that is used to calculate metrics \n",
    "        in brainx. Uses weighted partition object \n",
    "        stuff (add GraphPartition if you want to \n",
    "        use brainx metrics using GraphPartition)\n",
    "        '''\n",
    "        if runLouvain:\n",
    "            louvain=LouvainCommunityDetection(graph=self.graph,\n",
    "                                              communities=self.community_sets)\n",
    "            partitions=louvain.run()\n",
    "            self.graphpartition=partitions[-1]\n",
    "        else:\n",
    "            self.graphpartition=wmod.WeightedPartition(\n",
    "                self.graph,self.community_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###node-wise statistics\n",
    "'''\n",
    "See The modular and integrative functional architecture of the human brain\n",
    "Bertolero , Yeo , and D'Esposito\n",
    "'''\n",
    "def calc_node_participation_coeff(graphpart):\n",
    "    '''Participation coefficient is a measure of diversity of \n",
    "    intermodular connections of individual nodes.\n",
    "    \n",
    "    The function is from brainx and uses the weights from the\n",
    "    networkx graph (within the GraphPartition object). \n",
    "    \n",
    "    Thus, if binary weights desired (set weights of edges all to 1)\n",
    "    '''\n",
    "    node_part_coef=participation_coefficient(\n",
    "        graphpart,\n",
    "        edgeless =np.nan,\n",
    "        catch_edgeless_node=False)\n",
    "    return pd.Series(node_part_coef,name='p_coef')\n",
    "\n",
    "def calc_node_within_community_degree(graphpart):\n",
    "    '''Within community degree z score\n",
    "    '''\n",
    "    node_within_degree=within_community_degree(\n",
    "        graphpart,\n",
    "        edgeless=np.nan,\n",
    "        catch_edgeless_node=False)\n",
    "    return pd.Series(node_within_degree,name='node_within_degree')\n",
    "\n",
    "def calc_node_degree(graph):\n",
    "    '''Node degree is the number of links connected to the node\n",
    "    Binarized matrices (for weighted, this is strength)\n",
    "    \n",
    "    If binary desired, set weights to 1.\n",
    "    '''\n",
    "    node_degree=weighted_degree(graph)\n",
    "    return pd.Series(node_degree,name='node_degree')\n",
    "\n",
    "def calc_modularity(graphpart):\n",
    "    modularity=graphpart.modularity()\n",
    "    return {'modularity':modularity}\n",
    "\n",
    "def get_communities(graphpart):\n",
    "    community_sets=enumerate(graphpart.communities)\n",
    "    return pd.Series(\n",
    "        {node:i for i,setlist in community_sets\n",
    "         for node in setlist},\n",
    "        name='communities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#not using......\n",
    "def init_Edges(sub,ftype='rest',mscrub='0.5',nuis_global='global1',\n",
    "              get_community=None):\n",
    "    '''initiate the edge object and add 7 network Yeo community sets based on\n",
    "    a network name string key: network index integer values\n",
    "    '''\n",
    "    subint=int(re.findall('\\d+',sub)[0])\n",
    "    edge=Edge(\n",
    "        sub=subint,\n",
    "        adjcsvdir=funcpath+\n",
    "        sub+'/'+ftype+'/average/_threshold_'+mscrub+'/'\n",
    "        '_compcor_ncomponents_5_selector_pc10.'\n",
    "        'linear1.wm1.'+nuis_global+'.motion1.quadratic1.gm0.compcor0.csf1/'\n",
    "        '_bandpass_freqs_0.009.0.1/'\n",
    "        'bh.Schaefer2018_400Parcels_7Networks_fsaverage5_zcorr.csv')\n",
    "    #add community indices and sets\n",
    "    if get_community:\n",
    "        edge.add_community_sets(annotpwd=annotpwd,\n",
    "                                community_key=network7_key)\n",
    "        edge.format_adj_df(['parc_x','net_x'])\n",
    "    else:\n",
    "        edge.community_sets=None\n",
    "        edge.format_adj_df()\n",
    "    return edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_Edges(edgeobj,cost=None):\n",
    "    '''make a pd.Series of unique edges in adj_df\n",
    "    if reusing an edge object, it makes new Graph/GraphPartition.\n",
    "    objects based on threshold\n",
    "    '''\n",
    "    binary=None\n",
    "    edgeobj.threshold=None\n",
    "    edgeobj.cost=None\n",
    "    if cost:\n",
    "        edgeobj.find_thresh_edges(cost)\n",
    "        #binary=True\n",
    "    #normalize edges (no negative edges allowed in brainx)\n",
    "    edgeobj.make_nxGraph(binary=binary)\n",
    "    edgeobj.add_GraphPartition(runLouvain=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_Metrics(edgeobj,cost):\n",
    "    '''updates an Edge object based on\n",
    "    a threshold (with the run_Edge fxn)\n",
    "    and then computes node-wise graph metrics\n",
    "    from the brainx GraphPartition obj, the \n",
    "    graph, or the pd.Series.\n",
    "    '''\n",
    "    run_Edges(edgeobj,cost)\n",
    "    sub=edgeobj.sub\n",
    "    graph=edgeobj.graph\n",
    "    graphpart=edgeobj.graphpartition\n",
    "    edgeseries=edgeobj.edges_series\n",
    "    cost=edgeobj.cost\n",
    "    thresh=edgeobj.threshold\n",
    "    communities=graphpart.communities\n",
    "    \n",
    "    node_metrics_df=(pd.DataFrame([\n",
    "        calc_node_participation_coeff(graphpart),\n",
    "        calc_node_within_community_degree(graphpart),\n",
    "        get_communities(graphpart)])\n",
    "                     .T.rename_axis(['parc_label']))\n",
    "    \n",
    "    index_columns={'subs':sub,'cost':cost,'threshold':thresh,\n",
    "                  'num_communities':len(communities)}\n",
    "    other_sub_metrics=calc_modularity(graphpart)\n",
    "    sub_metrics_df=(pd.DataFrame(node_metrics_df.mean(axis=0))\n",
    "                    .T       \n",
    "                    .assign(**other_sub_metrics)\n",
    "                    .assign(**index_columns))\n",
    "    \n",
    "    return (node_metrics_df.assign(**index_columns),\n",
    "            sub_metrics_df,\n",
    "           edgeobj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def concat_Metrics(sub,cost_List,n_jobs=1):\n",
    "    '''runs the run_Metrics for a \n",
    "    list of subs after formatting Edge object'''\n",
    "    subedges=init_Edges(sub=sub)\n",
    "    metrics_tuple=Parallel(n_jobs)(\n",
    "        delayed(run_Metrics)\n",
    "        (copy.deepcopy(subedges),cost)\n",
    "        for cost in cost_List)\n",
    "    node_metrics=pd.concat(x[0] for x in metrics_tuple)\n",
    "    sub_metrics=pd.concat(x[1] for x in metrics_tuple)\n",
    "    sub_edgeobjs={x[2].cost:x[2] for x in metrics_tuple}\n",
    "    return (node_metrics,sub_metrics,sub_edgeobjs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_subs_runList(ftype,datapwd):\n",
    "    '''create a list of subject folders to\n",
    "     include (these strs are used for input into\n",
    "     the init_Edge fxn for initiating metric calculations\n",
    "     with Edge class obj.)'''\n",
    "    FDthresh={'memory':'50','rest':'10'}\n",
    "    maxdisp={'memory':'4','rest':'50'}\n",
    "    md=maxdisp[ftype]\n",
    "    FDt=FDthresh[ftype]\n",
    "    power_df=pd.read_csv(datapwd+ftype+'/power_params_allsubs.csv')\n",
    "    motion_df=pd.read_csv(datapwd+ftype+'/motion_params_allsubs.csv')\n",
    "    subs_runs=(motion_df\n",
    "               .merge(power_df,on=['Subject','Scan'])\n",
    "               .query('Max_Abs_Maxdisp<{} &'\n",
    "                      'PercentFDgreaterthan050<{}'.format(md,FDt)))\n",
    "    subs_runs['run']=subs_runs.Scan.str.extractall('(\\d\\d\\d)').values\n",
    "    #create subs and good runs groupby object iterator\n",
    "    subs_run_groupby=(subs_runs\n",
    "                  .groupby(['Subject'])\n",
    "                  .apply(lambda x: x.run.values)\n",
    "                  .groupby(level=0))\n",
    "    subs_List=[sub for sub,runList in subs_run_groupby]\n",
    "    return subs_List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subs_List=create_subs_runList('rest',('/Volumes/Users/mbkranz/projects/'\n",
    "                            'git_repo_backups/'\n",
    "                            'individual_diff_func_conn_corticalthick/data/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "funcpath='/Volumes/Users/mbkranz/projects/ACT_Freesurfer_Func/'\n",
    "gitpath=('/Volumes/Users/mbkranz/projects/git_repo_backups/'\n",
    "          'individual_diff_func_conn_corticalthick/')\n",
    "annotpwd=(gitpath+\n",
    "          'parcellations/schaefer2018/FreeSurfer5.3/'\n",
    "          'fsaverage5/label/'\n",
    "          '{}.Schaefer2018_400Parcels_7Networks_order.annot')\n",
    "adjcsv_name='bh.Schaefer2018_400Parcels_7Networks_fsaverage5_zcorr.csv'\n",
    "hemi_key={'lh':0,'rh':1}\n",
    "network7_key={n:i for i,n in enumerate(\n",
    "    ['Medial_Wall','Vis','SomMot','DorsAttn',\n",
    "     'SalVentAttn','Limbic','Cont','Default'])}\n",
    "community_key={}\n",
    "cost_List=list(np.arange(.05,.2,.01))\n",
    "ftype='rest'\n",
    "mscrub='0.5'\n",
    "nuis_global='global1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with ACT08_1Time: 587.360948086\n",
      "Done with ACT09_1Time: 580.400264978\n",
      "Done with ACT11_1Time: 553.179049015\n",
      "Done with ACT12_1Time: 519.946748018\n",
      "Done with ACT13_1Time: 557.218665123\n",
      "Done with ACT16_1Time: 560.313765049\n",
      "Done with ACT18_1Time: 576.597196102\n",
      "Done with ACT20_1Time: 598.121393919\n",
      "Done with ACT21_1Time: 694.80591917\n",
      "Done with ACT22_1Time: 627.807766914\n",
      "Done with ACT23_1Time: 536.605708122\n",
      "Done with ACT24_1Time: 738.382025957\n",
      "Done with ACT25_1Time: 578.761958838\n",
      "Done with ACT6001_1Time: 548.20156002\n",
      "Done with ACT6002_1Time: 495.37273407\n",
      "Done with ACT6004_1Time: 626.953985929\n",
      "Done with ACT6005_1Time: 533.547255993\n",
      "Done with ACT6006_1Time: 563.72242403\n",
      "Done with ACT6009_1Time: 556.806764126\n",
      "Done with ACT6011_1Time: 604.169834852\n",
      "Done with ACT6014_1Time: 476.363862038\n",
      "Done with ACT6015_1Time: 486.242815018\n",
      "Done with ACT6016_1Time: 494.463088989\n",
      "Done with ACT6017_1Time: 632.533671141\n",
      "Done with ACT6018_1Time: 616.746487856\n",
      "Done with ACT6019_1Time: 563.55942297\n",
      "Done with ACT6020_1Time: 512.861700058\n",
      "Done with ACT6021_1Time: 685.298985004\n",
      "Done with ACT6022_1Time: 537.703086853\n",
      "Done with ACT6024_1Time: 560.615983963\n",
      "Done with ACT6025_1Time: 619.745124102\n",
      "Done with ACT6026_1Time: 565.701472044\n",
      "Done with ACT6027_1Time: 545.739486933\n",
      "Done with ACT6028_1Time: 530.123411894\n",
      "Done with ACT6029_1Time: 536.559120893\n",
      "Done with ACT6030_1Time: 525.099884033\n",
      "Done with ACT6031_1Time: 520.746679068\n",
      "Done with ACT6033_1Time: 589.578582048\n",
      "Done with ACT6036_1Time: 476.231627941\n",
      "Done with ACT6038_1Time: 582.878160954\n",
      "Done with ACT6041_1Time: 618.275338888\n",
      "Done with ACT6042_1Time: 524.96391201\n",
      "Done with ACT6044_1Time: 519.295452118\n",
      "Done with ACT6047_1Time: 513.078277111\n",
      "Done with ACT6048_1Time: 549.632012129\n",
      "Done with ACT6049_1Time: 526.192128897\n",
      "Done with ACT6051_1Time: 536.647711039\n",
      "Done with ACT6052_1Time: 761.555804968\n",
      "Done with ACT6054_1Time: 630.03116703\n",
      "Done with ACT6058_1Time: 581.078767061\n",
      "Done with ACT6059_1Time: 568.784958839\n",
      "Done with ACT6062_1Time: 720.505427837\n",
      "Done with ACT6063_1Time: 540.605672121\n",
      "Done with ACT6064_1Time: 572.551359892\n",
      "Done with ACT6065_1Time: 540.16435504\n",
      "Done with ACT6066_1Time: 533.1732831\n",
      "Done with ACT6067_1Time: 635.639962912\n",
      "Done with ACT6069_1Time: 565.484836102\n",
      "Done with ACT6070_1Time: 574.461170912\n",
      "Done with ACT6074_1Time: 529.51970005\n",
      "Done with ACT6075_1Time: 500.23385787\n",
      "Done with ACT6076_1Time: 605.043760061\n",
      "Done with ACT6078_1Time: 608.098883152\n",
      "Done with ACT6080_1Time: 540.911221981\n",
      "Done with ACT6081_1Time: 652.64716506\n",
      "Done with ACT6083_1Time: 534.519531012\n",
      "Done with ACT6084_1Time: 569.340052128\n",
      "Done with ACT6085_1Time: 544.315345049\n",
      "Done with ACT6087_1Time: 563.990270138\n",
      "Done with ACT6089_1Time: 530.580847979\n",
      "Done with ACT6090_1Time: 564.537689924\n",
      "Done with ACT6092_1Time: 530.128650904\n",
      "Done with ACT6093_1Time: 516.323781013\n"
     ]
    }
   ],
   "source": [
    "#run and save node metrics with Louvain community detection\n",
    "for sub in subs_List:\n",
    "    starttime=time.time()\n",
    "    funcdir=(funcpath+sub+'/'+ftype+'/average/_threshold_'+mscrub+'/'\n",
    "    '_compcor_ncomponents_5_selector_pc10.'\n",
    "    'linear1.wm1.'+nuis_global+'.motion1.quadratic1.gm0.compcor0.csf1/'\n",
    "    '_bandpass_freqs_0.009.0.1/')\n",
    "    \n",
    "    subint=int(re.findall('\\d+',sub)[0])\n",
    "    edge=Edge(sub=subint,adjcsvdir=funcdir+adjcsv_name)\n",
    "    edge.community_sets=None\n",
    "    edge.format_adj_df()\n",
    "    node_mets,sub_mets,edgeobjs=concat_Metrics(sub,cost_List,n_jobs=16)\n",
    "    node_mets.to_csv(funcdir+'node_metrics_Louvain.csv')\n",
    "    sub_mets.to_csv(funcdir+'sub_metrics_Louvain.csv')\n",
    "    f=open(funcdir+'edge_object_Louvain.pkl','wb')\n",
    "    pkl.dump(edgeobjs,f)\n",
    "    f.close()\n",
    "    print('Done with '+sub+'Time: '+str(time.time()-starttime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unthresholded metrics (but from community structure based on Louvain comm detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def merge_edges_communities(edge_df,comms):\n",
    "    node_comms=pd.DataFrame([[comm,node] \n",
    "                             for comm,node_set in enumerate(comms) \n",
    "                             for node in node_set],\n",
    "                            columns=['community','parc'])\n",
    "    edge_comms_df=(edge_df.reset_index()\n",
    "                   .merge(right=node_comms,left_on='parc_x',right_on='parc',how='left')\n",
    "                   .drop(['parc'],axis=1)\n",
    "                   .merge(right=node_comms,left_on='parc_y',right_on='parc',how='left')\n",
    "                   .drop(['parc'],axis=1))\n",
    "    return edge_comms_df\n",
    "\n",
    "def _compute_unthresh_stats(df,node):\n",
    "    '''compute mean within network and between network average connectivity\n",
    "    for an individual node from the edge series with a community index\n",
    "    '''\n",
    "    edge_node_df=df.query('parc_x=={} | parc_y=={}'\n",
    "                                  .format(str(node),str(node)))\n",
    "    within_str='community_x==community_y'\n",
    "    btw_str='community_x!=community_y'\n",
    "    within=edge_node_df.query(within_str)['weight'].mean()\n",
    "    between=edge_node_df.query(btw_str)['weight'].mean()\n",
    "    return {'parc_label':node,\n",
    "            'within_strength':within,\n",
    "            'between_strength':between}\n",
    "\n",
    "def calc_unthresh_metrics(edge_df_wcomms,sub,cost):\n",
    "    '''\n",
    "    - for each node calc between sys, within sys strength\n",
    "    with an edge series of all edges and community indices\n",
    "    - label outputted df with a cost (if applicable) and subject\n",
    "    '''\n",
    "    node_copies=(edge_df_wcomms\n",
    "                 .filter(['parc_x','parc_y'])\n",
    "                 .values.flatten())\n",
    "    nodes=np.unique(node_copies)\n",
    "    stats=[_compute_unthresh_stats(edge_df_wcomms,node) for node in nodes]\n",
    "    return pd.DataFrame(stats).assign(subs=sub,cost=cost)\n",
    "\n",
    "def save_unthresh_metrics(sub):\n",
    "    #load dict containing Edge objects (key is threshold,item is Edge object)\n",
    "    funcdir=(funcpath+sub+'/'+ftype+'/average/_threshold_'+mscrub+'/'\n",
    "         '_compcor_ncomponents_5_selector_pc10.'\n",
    "         'linear1.wm1.'+nuis_global+'.motion1.quadratic1.gm0.compcor0.csf1/'\n",
    "         '_bandpass_freqs_0.009.0.1/')\n",
    "    edgeobjs=pkl.load(open(funcdir+'edge_object_Louvain.pkl'))\n",
    "    #make a list of dicts with key,items representing input into \n",
    "    #calc_unthresh_metrics (using splat operator)\n",
    "    edge_dict_list=[{\n",
    "            'sub':int(re.findall('\\d+',sub)[0]),\n",
    "            'cost':cost,\n",
    "            'edge_df_wcomms':merge_edges_communities(\n",
    "                edgeobj.edges_series,edgeobj.graphpartition.communities)\n",
    "            } for cost,edgeobj in edgeobjs.iteritems()]\n",
    "    #get list of dataframes with metrics\n",
    "    edge_metrics=[calc_unthresh_metrics(**edge_dict) \n",
    "                  for edge_dict in edge_dict_list]\n",
    "    pd.concat(edge_metrics).to_csv(funcdir+'node_metrics_Louvain_unthresh.csv')\n",
    "    return sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ACT01_1',\n",
       " 'ACT04_1',\n",
       " 'ACT05_1',\n",
       " 'ACT07_1',\n",
       " 'ACT08_1',\n",
       " 'ACT09_1',\n",
       " 'ACT11_1',\n",
       " 'ACT12_1',\n",
       " 'ACT13_1',\n",
       " 'ACT16_1',\n",
       " 'ACT18_1',\n",
       " 'ACT20_1',\n",
       " 'ACT21_1',\n",
       " 'ACT22_1',\n",
       " 'ACT23_1',\n",
       " 'ACT24_1',\n",
       " 'ACT25_1',\n",
       " 'ACT6001_1',\n",
       " 'ACT6002_1',\n",
       " 'ACT6004_1',\n",
       " 'ACT6005_1',\n",
       " 'ACT6006_1',\n",
       " 'ACT6009_1',\n",
       " 'ACT6011_1',\n",
       " 'ACT6014_1',\n",
       " 'ACT6015_1',\n",
       " 'ACT6016_1',\n",
       " 'ACT6017_1',\n",
       " 'ACT6018_1',\n",
       " 'ACT6019_1',\n",
       " 'ACT6020_1',\n",
       " 'ACT6021_1',\n",
       " 'ACT6022_1',\n",
       " 'ACT6024_1',\n",
       " 'ACT6025_1',\n",
       " 'ACT6026_1',\n",
       " 'ACT6027_1',\n",
       " 'ACT6028_1',\n",
       " 'ACT6029_1',\n",
       " 'ACT6030_1',\n",
       " 'ACT6031_1',\n",
       " 'ACT6033_1',\n",
       " 'ACT6036_1',\n",
       " 'ACT6038_1',\n",
       " 'ACT6041_1',\n",
       " 'ACT6042_1',\n",
       " 'ACT6044_1',\n",
       " 'ACT6047_1',\n",
       " 'ACT6048_1',\n",
       " 'ACT6049_1',\n",
       " 'ACT6051_1',\n",
       " 'ACT6052_1',\n",
       " 'ACT6054_1',\n",
       " 'ACT6058_1',\n",
       " 'ACT6059_1',\n",
       " 'ACT6062_1',\n",
       " 'ACT6063_1',\n",
       " 'ACT6064_1',\n",
       " 'ACT6065_1',\n",
       " 'ACT6066_1',\n",
       " 'ACT6067_1',\n",
       " 'ACT6069_1',\n",
       " 'ACT6070_1',\n",
       " 'ACT6074_1',\n",
       " 'ACT6075_1',\n",
       " 'ACT6076_1',\n",
       " 'ACT6078_1',\n",
       " 'ACT6080_1',\n",
       " 'ACT6081_1',\n",
       " 'ACT6083_1',\n",
       " 'ACT6084_1',\n",
       " 'ACT6085_1',\n",
       " 'ACT6087_1',\n",
       " 'ACT6089_1',\n",
       " 'ACT6090_1',\n",
       " 'ACT6092_1',\n",
       " 'ACT6093_1',\n",
       " 'ACT6094_1',\n",
       " 'ACT6099_1',\n",
       " 'ACT6100_1',\n",
       " 'ACT6101_1',\n",
       " 'ACT6102_1',\n",
       " 'ACT6103_1',\n",
       " 'ACT6104_1',\n",
       " 'ACT6105_1',\n",
       " 'ACT6106_1',\n",
       " 'ACT6107_1',\n",
       " 'ACT6111_1',\n",
       " 'ACT6112_1',\n",
       " 'ACT6113_1',\n",
       " 'ACT6114_1',\n",
       " 'ACT6115_1',\n",
       " 'ACT6117_1',\n",
       " 'ACT6119_1',\n",
       " 'ACT6120_1',\n",
       " 'ACT6121_1',\n",
       " 'ACT6122_1',\n",
       " 'ACT6124_1',\n",
       " 'ACT6126_1',\n",
       " 'ACT6127_1',\n",
       " 'ACT6128_1',\n",
       " 'ACT6129_1',\n",
       " 'ACT6130_1',\n",
       " 'ACT6131_1',\n",
       " 'ACT6132_1',\n",
       " 'ACT6133_1',\n",
       " 'ACT6134_1',\n",
       " 'ACT6136_1',\n",
       " 'ACT6140_1',\n",
       " 'ACT6141_1',\n",
       " 'ACT6145_1',\n",
       " 'ACT6147_1',\n",
       " 'ACT6150_1',\n",
       " 'ACT6151_1',\n",
       " 'ACT6153_1',\n",
       " 'ACT6154_1',\n",
       " 'ACT6157_1',\n",
       " 'ACT6159_1',\n",
       " 'ACT6160_1',\n",
       " 'ACT6161_1',\n",
       " 'ACT6163_1',\n",
       " 'ACT6166_1',\n",
       " 'ACT6168_1',\n",
       " 'ACT6169_1',\n",
       " 'ACT6170_1',\n",
       " 'ACT6171_1',\n",
       " 'ACT6172_1',\n",
       " 'ACT6175_1',\n",
       " 'ACT6177_1',\n",
       " 'ACT6178_1',\n",
       " 'ACT6179_1',\n",
       " 'ACT6182_1',\n",
       " 'ACT6186_1',\n",
       " 'ACT6187_1',\n",
       " 'ACT6190_1',\n",
       " 'ACT6191_1',\n",
       " 'ACT6192_1',\n",
       " 'ACT6193_1',\n",
       " 'ACT6194_1',\n",
       " 'ACT6198_1',\n",
       " 'ACT6199_1',\n",
       " 'ACT6201_1',\n",
       " 'ACT6202_1',\n",
       " 'ACT6204_1',\n",
       " 'ACT6206_1',\n",
       " 'ACT6207_1',\n",
       " 'ACT6209_1',\n",
       " 'ACT6210_1',\n",
       " 'ACT6214_1',\n",
       " 'ACT6215_1',\n",
       " 'ACT6216_1',\n",
       " 'ACT6217_1',\n",
       " 'ACT6218_1',\n",
       " 'ACT6219_1']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Parallel(8)(delayed(save_unthresh_metrics)(\n",
    "    sub) for sub in subs_List)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yeo pre-defined unthresholded metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_community_sets(annotpwd,community_key):\n",
    "    '''\n",
    "    make a group annotation of a network parcellation into a list of sets\n",
    "    \n",
    "    returns a np.array list of communities from \n",
    "    Freesurfer annotations files for both hemispheres\n",
    "    - note, for Freesurfer, index starts at 1 as 0 is medial wall but need \n",
    "    index to be 0 (so now network 1 is indexed as 0)\n",
    "    '''\n",
    "    def get_onehemi(hemi):\n",
    "        #loads annotation integer labels (numpy array) for one hemi\n",
    "        annot=fs.read_annot(annotpwd.format(hemi))\n",
    "\n",
    "        community_labels=(pd.Series([x.astype(str).split('_')[2] \n",
    "                          for x in annot[2][1:]])\n",
    "                .map(community_key))\n",
    "        return community_labels.values\n",
    "\n",
    "    hemiList=['lh','rh']\n",
    "    net_labs=np.vstack([get_onehemi(hemi) \n",
    "                        for hemi in hemiList]).flatten()\n",
    "    labs=pd.DataFrame({'parc':range(len(net_labs)),\n",
    "                    'net':net_labs})\n",
    "    community_sets=[set(x['parc'].values) \n",
    "                    for group,x in labs.groupby(['net'])]\n",
    "    return community_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
      " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 7 7 7 7 7 7 7 7 7\n",
      " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7]\n"
     ]
    }
   ],
   "source": [
    "yeo_communities=add_community_sets(annotpwd,network7_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#run and save node metrics with pre-defined Yeo parcellation\n",
    "def get_unthresh_metrics_yeo(sub):\n",
    "    starttime=time.time()\n",
    "    funcdir=(funcpath+sub+'/'+ftype+'/average/_threshold_'+mscrub+'/'\n",
    "    '_compcor_ncomponents_5_selector_pc10.'\n",
    "    'linear1.wm1.'+nuis_global+'.motion1.quadratic1.gm0.compcor0.csf1/'\n",
    "    '_bandpass_freqs_0.009.0.1/')\n",
    "    subint=int(re.findall('\\d+',sub)[0])\n",
    "    edge=Edge(sub=subint,adjcsvdir=funcdir+adjcsv_name)\n",
    "    edge.format_adj_df()\n",
    "    edge_df_wcomms=merge_edges_communities(edge.edges_series,yeo_communities)\n",
    "    node_metrics=calc_unthresh_metrics(edge_df_wcomms=edge_df_wcomms,\n",
    "                          cost=None,sub=subint)\n",
    "    print('Done with '+sub+'Time: '+str(time.time()-starttime))\n",
    "    return node_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with ACT08_1Time: 4.92322897911\n",
      "Done with ACT07_1Time: 4.92374610901\n",
      "Done with ACT01_1Time: 4.99646306038\n",
      "Done with ACT12_1Time: 5.0005838871\n",
      "Done with ACT04_1Time: 5.00756502151\n",
      "Done with ACT09_1Time: 5.01227402687\n",
      "Done with ACT05_1Time: 5.01751208305\n",
      "Done with ACT11_1Time: 5.02140307426\n",
      "Done with ACT13_1Time: 4.91984891891\n",
      "Done with ACT16_1Time: 4.93030500412\n",
      "Done with ACT18_1Time: 4.97618103027\n",
      "Done with ACT20_1Time: 5.04828000069\n",
      "Done with ACT22_1Time: 5.04312896729\n",
      "Done with ACT23_1Time: 5.04029393196\n",
      "Done with ACT24_1Time: 5.04429292679\n",
      "Done with ACT21_1Time: 5.06719684601\n",
      "Done with ACT25_1Time: 4.9527759552\n",
      "Done with ACT6001_1Time: 4.95472693443\n",
      "Done with ACT6002_1Time: 4.97664999962\n",
      "Done with ACT6004_1Time: 4.95423197746\n",
      "Done with ACT6005_1Time: 5.010627985\n",
      "Done with ACT6011_1Time: 4.99843192101\n",
      "Done with ACT6009_1Time: 5.01655912399\n",
      "Done with ACT6006_1Time: 5.03986001015\n",
      "Done with ACT6014_1Time: 4.88456702232\n",
      "Done with ACT6015_1Time: 4.90848112106\n",
      "Done with ACT6016_1Time: 4.86671805382\n",
      "Done with ACT6017_1Time: 4.86090302467\n",
      "Done with ACT6018_1Time: 4.9532020092\n",
      "Done with ACT6019_1Time: 4.99352288246\n",
      "Done with ACT6020_1Time: 5.00619506836\n",
      "Done with ACT6021_1Time: 5.00657510757\n",
      "Done with ACT6022_1Time: 4.85349583626\n",
      "Done with ACT6024_1Time: 4.83004999161\n",
      "Done with ACT6025_1Time: 4.82663798332\n",
      "Done with ACT6026_1Time: 4.81544804573\n",
      "Done with ACT6027_1Time: 4.81605577469\n",
      "Done with ACT6028_1Time: 4.84287905693\n",
      "Done with ACT6029_1Time: 4.83597588539\n",
      "Done with ACT6030_1Time: 4.82646012306\n",
      "Done with ACT6031_1Time: 4.78146600723\n",
      "Done with ACT6033_1Time: 4.81370806694\n",
      "Done with ACT6036_1Time: 4.8071000576\n",
      "Done with ACT6038_1Time: 4.79904508591\n",
      "Done with ACT6041_1Time: 4.82138800621\n",
      "Done with ACT6042_1Time: 4.83836603165\n",
      "Done with ACT6044_1Time: 4.83317494392\n",
      "Done with ACT6047_1Time: 4.84333491325\n",
      "Done with ACT6048_1Time: 4.84065890312\n",
      "Done with ACT6049_1Time: 4.8846180439\n",
      "Done with ACT6052_1Time: 4.85893201828\n",
      "Done with ACT6051_1Time: 4.89084887505\n",
      "Done with ACT6054_1Time: 4.83338999748\n",
      "Done with ACT6058_1Time: 4.9069750309\n",
      "Done with ACT6059_1Time: 4.91202902794\n",
      "Done with ACT6062_1Time: 4.92908787727\n",
      "Done with ACT6063_1Time: 4.73698306084\n",
      "Done with ACT6064_1Time: 4.76698589325\n",
      "Done with ACT6066_1Time: 4.79059410095\n",
      "Done with ACT6065_1Time: 4.80314207077\n",
      "Done with ACT6067_1Time: 4.76622414589\n",
      "Done with ACT6069_1Time: 4.85572695732\n",
      "Done with ACT6070_1Time: 4.84349489212\n",
      "Done with ACT6074_1Time: 4.83572912216\n",
      "Done with ACT6075_1Time: 4.77551102638\n",
      "Done with ACT6076_1Time: 4.78084397316\n",
      "Done with ACT6078_1Time: 4.81382989883\n",
      "Done with ACT6080_1Time: 4.81675410271\n",
      "Done with ACT6081_1Time: 4.78333806992\n",
      "Done with ACT6083_1Time: 4.78205323219\n",
      "Done with ACT6084_1Time: 4.8226211071\n",
      "Done with ACT6085_1Time: 4.81222200394\n",
      "Done with ACT6087_1Time: 4.76604008675\n",
      "Done with ACT6089_1Time: 4.77069997787\n",
      "Done with ACT6090_1Time: 4.7840950489\n",
      "Done with ACT6092_1Time: 4.80227899551\n",
      "Done with ACT6093_1Time: 4.77643013\n",
      "Done with ACT6094_1Time: 4.76673984528\n",
      "Done with ACT6099_1Time: 4.77328491211\n",
      "Done with ACT6100_1Time: 4.78252792358\n",
      "Done with ACT6101_1Time: 4.82585406303\n",
      "Done with ACT6102_1Time: 4.86115598679\n",
      "Done with ACT6103_1Time: 4.86272096634\n",
      "Done with ACT6104_1Time: 4.84226298332\n",
      "Done with ACT6105_1Time: 4.85974001884\n",
      "Done with ACT6106_1Time: 4.88507914543\n",
      "Done with ACT6107_1Time: 4.89067482948\n",
      "Done with ACT6111_1Time: 4.88669419289\n",
      "Done with ACT6112_1Time: 4.77082419395\n",
      "Done with ACT6113_1Time: 4.76883602142\n",
      "Done with ACT6114_1Time: 4.79734706879\n",
      "Done with ACT6115_1Time: 4.78678798676\n",
      "Done with ACT6117_1Time: 4.7945702076\n",
      "Done with ACT6119_1Time: 4.7955467701\n",
      "Done with ACT6120_1Time: 4.79323196411\n",
      "Done with ACT6121_1Time: 4.79997014999\n",
      "Done with ACT6122_1Time: 4.82620286942\n",
      "Done with ACT6124_1Time: 4.81575989723\n",
      "Done with ACT6126_1Time: 4.82959079742\n",
      "Done with ACT6127_1Time: 4.84163713455\n",
      "Done with ACT6128_1Time: 4.82058215141\n",
      "Done with ACT6129_1Time: 4.80867600441\n",
      "Done with ACT6130_1Time: 4.81621479988\n",
      "Done with ACT6131_1Time: 4.80534911156\n",
      "Done with ACT6132_1Time: 4.95535302162\n",
      "Done with ACT6133_1Time: 4.91743993759\n",
      "Done with ACT6134_1Time: 4.92046189308\n",
      "Done with ACT6136_1Time: 4.91289401054\n",
      "Done with ACT6140_1Time: 4.93283987045\n",
      "Done with ACT6141_1Time: 4.9306910038\n",
      "Done with ACT6145_1Time: 4.94240093231\n",
      "Done with ACT6147_1Time: 4.95662403107\n",
      "Done with ACT6150_1Time: 4.84389615059\n",
      "Done with ACT6151_1Time: 4.88708996773\n",
      "Done with ACT6153_1Time: 4.86271500587\n",
      "Done with ACT6154_1Time: 4.87792205811\n",
      "Done with ACT6157_1Time: 4.84479308128\n",
      "Done with ACT6159_1Time: 4.84812998772\n",
      "Done with ACT6160_1Time: 4.85327506065\n",
      "Done with ACT6161_1Time: 4.85453605652\n",
      "Done with ACT6163_1Time: 4.91195082664\n",
      "Done with ACT6166_1Time: 4.92155003548\n",
      "Done with ACT6168_1Time: 4.94896602631\n",
      "Done with ACT6169_1Time: 4.94298291206\n",
      "Done with ACT6170_1Time: 4.94927191734\n",
      "Done with ACT6171_1Time: 4.93814492226\n",
      "Done with ACT6172_1Time: 4.93946886063\n",
      "Done with ACT6175_1Time: 4.93103384972\n",
      "Done with ACT6177_1Time: 4.83389306068\n",
      "Done with ACT6178_1Time: 4.81950211525\n",
      "Done with ACT6179_1Time: 4.84202694893\n",
      "Done with ACT6182_1Time: 4.86290001869\n",
      "Done with ACT6186_1Time: 4.85643982887\n",
      "Done with ACT6187_1Time: 4.89924907684\n",
      "Done with ACT6190_1Time: 4.84633302689\n",
      "Done with ACT6191_1Time: 4.84074902534\n",
      "Done with ACT6192_1Time: 4.77838897705\n",
      "Done with ACT6193_1Time: 4.80170202255\n",
      "Done with ACT6194_1Time: 4.78064584732\n",
      "Done with ACT6198_1Time: 4.79676914215\n",
      "Done with ACT6199_1Time: 4.79750990868\n",
      "Done with ACT6201_1Time: 4.81578302383\n",
      "Done with ACT6202_1Time: 4.79643392563\n",
      "Done with ACT6204_1Time: 4.80788302422\n",
      "Done with ACT6206_1Time: 4.77429509163\n",
      "Done with ACT6207_1Time: 4.78227090836\n",
      "Done with ACT6209_1Time: 4.79076194763\n",
      "Done with ACT6210_1Time: 4.802754879\n",
      "Done with ACT6214_1Time: 4.80053091049\n",
      "Done with ACT6216_1Time: 4.79291796684\n",
      "Done with ACT6215_1Time: 4.82221698761\n",
      "Done with ACT6217_1Time: 4.79985284805\n",
      "Done with ACT6218_1Time: 4.4409070015\n",
      "Done with ACT6219_1Time: 4.43078994751\n"
     ]
    }
   ],
   "source": [
    "df_nodes_yeo_unthresh=pd.concat(Parallel(8)(delayed(get_unthresh_metrics_yeo)\n",
    "            (sub) for sub in subs_List))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(sub,filename):\n",
    "    funcdir=(funcpath+sub+'/'+ftype+'/average/_threshold_'+mscrub+'/'\n",
    "             '_compcor_ncomponents_5_selector_pc10.'\n",
    "             'linear1.wm1.'+nuis_global+'.motion1.quadratic1.gm0.compcor0.csf1/'\n",
    "             '_bandpass_freqs_0.009.0.1/')\n",
    "    return pd.read_csv(funcdir+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_data(df,filename):\n",
    "    funcdir=(gitpath+'data/'+ftype+'/average/_threshold_'+mscrub+'/'\n",
    "             '_compcor_ncomponents_5_selector_pc10.'\n",
    "             'linear1.wm1.'+nuis_global+'.motion1.quadratic1.gm0.compcor0.csf1/'\n",
    "             '_bandpass_freqs_0.009.0.1/')\n",
    "    return df.to_csv(funcdir+filename,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load subject and node data\n",
    "df_nodes=pd.concat(Parallel(5)(\n",
    "    delayed(load_data)\n",
    "    (sub=sub,filename='node_metrics_Louvain.csv')\n",
    "    for sub in subs_List))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_subs=pd.concat(Parallel(5)(\n",
    "    delayed(load_data)\n",
    "    (sub=sub,filename='sub_metrics_Louvain.csv')\n",
    "    for sub in subs_List))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load subject and node data\n",
    "df_nodes_unthresh=pd.concat(Parallel(5)(\n",
    "    delayed(load_data)\n",
    "    (sub=sub,filename='node_metrics_Louvain_unthresh.csv')\n",
    "    for sub in subs_List))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_data(df_nodes,'node_metrics_Louvain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_data(yeo_node_metrics_df,'node_metrics_Yeo_unthresh.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_data(df_subs.drop(['Unnamed: 0'],axis=1),'sub_metrics_Louvain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_data(df_nodes_unthresh.drop(['Unnamed: 0'],axis=1),'node_metrics_Louvain_unthresh.csv')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
