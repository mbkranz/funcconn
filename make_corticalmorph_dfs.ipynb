{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "\n",
    "- this notebook (1) concatenates preprocessed freesurfer data (i.e., resampled to fsaverage and smoothed for each subject), (2) adds annotation network labels (currently using the Yeo 7 Network annotation but can use any annotation file), and (3) filters by network and saves in pickle file\n",
    "- in a last part of this notebook, also loads the wholebrain fsaverage pickle file and calculates the wholebrain (ie., cortex) measures (surface area and thickness)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "#general packages used for data import etc\n",
    "from nibabel import freesurfer as fs\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os,glob\n",
    "import re\n",
    "from joblib import Parallel,delayed\n",
    "import cPickle as pkl\n",
    "idx=pd.IndexSlice\n",
    "datapath=('/Volumes/Users/mbkranz/projects/git_repo_backups/'\n",
    "          'individual_diff_func_conn_corticalthick/data/')\n",
    "#subject directory and subject list\n",
    "SUBJECTS_DIR=('/Volumes/Users/mbkranz/'\n",
    "              'projects/ACT_Freesurfer_NewProc/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(SUBJECTS_DIR)\n",
    "sublist=!ls -d ACT*_1\n",
    "#npdata from make_npdata_from_pca.R \n",
    "npdata_all=pd.read_csv(datapath+'npdata/np_all.csv',na_values='NA')\n",
    "#filter out all subs without behav data\n",
    "sublist_filt=[\n",
    "    x for x in sublist if int(re.sub(\"ACT0|ACT|_1\",\"\",x)) \n",
    "    in npdata_all['subs'].values and x!='ACT6142_1' #bad sub (see notes)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meas_key={'thickness':np.int(0),'area':np.int(1)}\n",
    "hemi_key={'lh':np.int(0),'rh':np.int(1)}\n",
    "net_key={'network'+str(net):net for net in [1,2,3,4,5,6,7]}\n",
    "net_key['wholebrain']=[1,2,3,4,5,6,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getmorph(sub,measure,fwhm='10'):\n",
    "    def get_onehemi(hemi):\n",
    "        path_data=(SUBJECTS_DIR+ sub+'/surf/'+\n",
    "                   hemi+'.'+measure+'.'+'fwhm'+fwhm+\n",
    "                   '.fsaverage.mgh')\n",
    "        morph_data=(nib.load(path_data)\n",
    "                    .get_data()\n",
    "                    .flatten())\n",
    "        morph_hemi=pd.DataFrame({\n",
    "            'subs':np.int(re.sub(\"ACT0|ACT|_1\",\"\",sub)),\n",
    "            'measure':meas_key[measure],\n",
    "            'hemi':hemi_key[hemi],\n",
    "            'value':morph_data})\n",
    "        return morph_hemi\n",
    "    \n",
    "    morph_df=pd.concat([get_onehemi(hemi) \n",
    "                for hemi in hemi_key.iterkeys()])\n",
    "    return (morph_df\n",
    "            .rename_axis('vertex_index')\n",
    "            .set_index(['hemi'],append=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getannot(annotpath):\n",
    "    '''loads and concatenates annotation files for \n",
    "    both hemispheres and sets vertex and hemi ids\n",
    "    as indices (keys to join with subject wise metrics)\n",
    "    '''\n",
    "    def get_onehemi(hemi):\n",
    "        annot_data=fs.read_annot(annotpath.format(hemi))\n",
    "        annot_hemi=pd.DataFrame({\n",
    "            \"annot_label\" : annot_data[0],\n",
    "            \"hemi\": hemi_key[hemi]})\n",
    "        return annot_hemi\n",
    "\n",
    "    annot_df=pd.concat(get_onehemi(hemi) \n",
    "                       for hemi in hemi_key.iterkeys())\n",
    "    return (annot_df\n",
    "            .rename_axis('vertex_index')\n",
    "            .set_index(['hemi'],append=True)\n",
    "            .reorder_levels(['vertex_index','hemi']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "annots=getannot(datapath.replace('data','parcellations')+\n",
    "                'schaefer2018/FreeSurfer5.3/fsaverage/label/'+\n",
    "                 '{}.Schaefer2018_400Parcels_17Networks_order.annot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def average_morph(sub,annots,measure):\n",
    "    morph=getmorph(sub,measure)\n",
    "    morph_groupby=(morph.join(annots)\n",
    "     .set_index(['subs','measure','annot_label'],append=True)\n",
    "     ['value']\n",
    "     .groupby(['subs','measure','hemi','annot_label']))\n",
    "    \n",
    "    if measure=='thickness':\n",
    "        morph_summary=morph_groupby.mean()\n",
    "    elif measure=='area':\n",
    "        morph_summary=morph_groupby.sum()\n",
    "    else:\n",
    "        ValueError('Needs to be either area or thickness')\n",
    "    return morph_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "morph_df_allsubs=pd.concat(Parallel(4)(\n",
    "    delayed(average_morph)\n",
    "    (sub,annots,meas)\n",
    "    for sub in sublist_filt\n",
    "    for meas in meas_key.iterkeys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "morph_df_allsubs_filt=(\n",
    "    morph_df_allsubs\n",
    "    .reset_index()\n",
    "    .query('annot_label!=0')\n",
    "    .assign(parc_label=lambda x: (x['annot_label']-1)+(x['hemi']*200),\n",
    "            measure=lambda x: x['measure'].map({0:'thickness',1:'area'})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "morph_df_allsubs_unstack=(morph_df_allsubs_filt\n",
    " .set_index(['subs','measure','hemi','annot_label','parc_label'])\n",
    " ['value']\n",
    " .unstack('measure')\n",
    " .reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "morph_df_allsubs_unstack.to_csv(datapath+'/morphometry/morph_df_400parc_allsubs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
